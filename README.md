# Football Video Dataset to YOLO Format Converter

Dá»± Ã¡n nÃ y chuyá»ƒn Ä‘á»•i dataset video bÃ³ng Ä‘Ã¡ cÃ³ annotations thÃ nh Ä‘á»‹nh dáº¡ng YOLO Ä‘á»ƒ training cÃ¡c mÃ´ hÃ¬nh object detection. Dataset Ä‘Æ°á»£c extract tá»« video files (.mp4) vÃ  annotation files (.json) Ä‘á»ƒ táº¡o ra images vÃ  labels tÆ°Æ¡ng á»©ng theo chuáº©n YOLO.

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
Deeplearning_videoDataset_footbal_createFormat/
â”œâ”€â”€ create_yolo_format_dataset.py    # Script chÃ­nh Ä‘á»ƒ chuyá»ƒn Ä‘á»•i dataset
â”œâ”€â”€ dataset.py                       # VOC Dataset class cho PyTorch
â”œâ”€â”€ data/
â”‚   â””â”€â”€ football/                    # ThÆ° má»¥c chá»©a dá»¯ liá»‡u gá»‘c
â”‚       â”œâ”€â”€ video1/
â”‚       â”‚   â”œâ”€â”€ *.mp4               # Video files
â”‚       â”‚   â””â”€â”€ *.json              # Annotation files
â”‚       â””â”€â”€ video2/
â”‚           â”œâ”€â”€ *.mp4
â”‚           â””â”€â”€ *.json
â””â”€â”€ football_yolo/                   # Output directory (Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng)
    â””â”€â”€ train/
        â”œâ”€â”€ images/                  # Extracted frames
        â””â”€â”€ labels/                  # YOLO format labels
```

## ğŸ¯ Má»¥c Ä‘Ã­ch

Dá»± Ã¡n nÃ y giáº£i quyáº¿t bÃ i toÃ¡n:
- **Input**: Video bÃ³ng Ä‘Ã¡ (.mp4) + Annotation files (.json) 
- **Output**: Dataset YOLO format vá»›i images vÃ  labels Ä‘á»ƒ train object detection models
- **Target objects**: PhÃ¡t hiá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng trong video bÃ³ng Ä‘Ã¡ (players, ball, etc.)

## ğŸ”§ YÃªu cáº§u há»‡ thá»‘ng

### Dependencies
```bash
pip install opencv-python
pip install torch torchvision
pip install numpy
```

### Cáº¥u trÃºc dá»¯ liá»‡u Ä‘áº§u vÃ o

**JSON Annotation Format:**
```json
{
  "images": [
    {
      "width": 1920,
      "height": 1080,
      "id": 1
    }
  ],
  "annotations": [
    {
      "image_id": 1,
      "category_id": 3,
      "bbox": [x, y, width, height]
    }
  ]
}
```

**Categories:**
- `category_id = 3`: Class 0 (trong YOLO format)
- `category_id > 3`: Class 1 (trong YOLO format)

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº·t dá»¯ liá»‡u theo cáº¥u trÃºc:
```
data/football/
â”œâ”€â”€ video_folder_1/
â”‚   â”œâ”€â”€ video.mp4
â”‚   â””â”€â”€ annotations.json
â”œâ”€â”€ video_folder_2/
â”‚   â”œâ”€â”€ video.mp4
â”‚   â””â”€â”€ annotations.json
```

### 2. Cháº¡y script chuyá»ƒn Ä‘á»•i

```bash
python create_yolo_format_dataset.py
```

### 3. Káº¿t quáº£

Script sáº½ táº¡o ra:
- **Images**: `football_yolo/train/images/` - CÃ¡c frame Ä‘Æ°á»£c extract tá»« video
- **Labels**: `football_yolo/train/labels/` - YOLO format labels tÆ°Æ¡ng á»©ng

**YOLO Label Format:**
```
class_id x_center y_center width height
```
Táº¥t cáº£ giÃ¡ trá»‹ Ä‘Æ°á»£c normalize vá» [0,1]

## ğŸ“Š Chi tiáº¿t ká»¹ thuáº­t

### create_yolo_format_dataset.py

**Chá»©c nÄƒng chÃ­nh:**
1. **Video Processing**: Äá»c tá»«ng frame tá»« video sá»­ dá»¥ng OpenCV
2. **Annotation Parsing**: Parse JSON annotations vÃ  lá»c objects (category_id > 2)
3. **Coordinate Conversion**: Chuyá»ƒn Ä‘á»•i bbox tá»« absolute coordinates sang YOLO format
4. **Data Export**: LÆ°u images (.jpg) vÃ  labels (.txt)

**CÃ´ng thá»©c chuyá»ƒn Ä‘á»•i coordinates:**
```python
# From absolute to normalized
xmin_norm = xmin / image_width
ymin_norm = ymin / image_height
width_norm = width / image_width  
height_norm = height / image_height

# Calculate center point
x_center = xmin_norm + width_norm/2
y_center = ymin_norm + height_norm/2
```

**Class mapping:**
```python
if obj["category_id"] == 3:
    cls = 0  # First class
else:
    cls = 1  # Second class
```

### dataset.py

**VOCDataset Class:**
- Káº¿ thá»«a tá»« `torchvision.datasets.VOCDetection`
- Há»— trá»£ 21 categories chuáº©n Pascal VOC
- Preprocessing cho PyTorch training
- Coordinate scaling theo image resize

**Features:**
- Data augmentation vá»›i transforms
- Bounding box scaling
- Label encoding
- PyTorch tensor output

## ğŸ® CÃ¡ch cháº¡y thá»­ nghiá»‡m

### Test VOC Dataset:
```python
from dataset import VOCDataset
from torchvision.transforms import Compose, Resize, ToTensor, Normalize

# Setup transforms
train_transform = Compose([
    Resize((416, 416)),
    ToTensor(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load dataset
dataset = VOCDataset(
    root="data/voc", 
    year="2012", 
    image_set="trainval", 
    download=False, 
    transform=train_transform
)

# Get sample
image, target = dataset[0]
print(f"Image shape: {image.shape}")
print(f"Target: {target}")
```

## ğŸ” Debugging & Kiá»ƒm tra

Trong `create_yolo_format_dataset.py` cÃ³ pháº§n code test (Ä‘Ã£ comment) Ä‘á»ƒ visualize bounding boxes:

```python
# Uncomment Ä‘á»ƒ kiá»ƒm tra bbox
# xmax = xmin + width
# ymax = ymin + height
# cv2.rectangle(frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), 
#               color=(255, 0, 255), thickness=1)
```

## ğŸ“ˆ Workflow

1. **Input Processing**: Scan thÆ° má»¥c `data/football` tÃ¬m video vÃ  annotation files
2. **Frame Extraction**: Extract tá»«ng frame tá»« video
3. **Annotation Matching**: Match annotations vá»›i frame tÆ°Æ¡ng á»©ng
4. **Object Filtering**: Chá»‰ láº¥y objects cÃ³ `category_id > 2`
5. **Format Conversion**: Chuyá»ƒn bbox sang YOLO format
6. **File Export**: LÆ°u image + label files

## ğŸ¯ Káº¿t quáº£ mong Ä‘á»£i

- **Images**: Format JPG, Ä‘Æ°á»£c Ä‘Ã¡nh sá»‘ theo pattern `{video_id}_{frame_number}.jpg`
- **Labels**: Format TXT, má»—i dÃ²ng lÃ  má»™t object vá»›i format YOLO
- **Structure**: Sáºµn sÃ ng Ä‘á»ƒ training vá»›i YOLO models (YOLOv5, YOLOv8, etc.)

## ğŸ”§ Customization

### Thay Ä‘á»•i output path:
```python
output_path = "your_custom_path"  # Thay Ä‘á»•i trong create_yolo_format_dataset.py
```

### Thay Ä‘á»•i class mapping:
```python
# Modify class assignment logic
if obj["category_id"] == 3:
    cls = 0
elif obj["category_id"] == 4:
    cls = 1
# Add more classes as needed
```

### Thay Ä‘á»•i image format:
```python
cv2.imwrite(os.path.join(output_path, "images", "{}_{}.png".format(video_id+1, counter)), frame)
```

## ğŸ“ Notes

- **Memory Usage**: Xá»­ lÃ½ video lá»›n cÃ³ thá»ƒ tá»‘n nhiá»u RAM
- **Processing Time**: Thá»i gian phá»¥ thuá»™c vÃ o Ä‘á»™ dÃ i video vÃ  sá»‘ lÆ°á»£ng annotations
- **Quality**: Output images giá»¯ nguyÃªn cháº¥t lÆ°á»£ng cá»§a video gá»‘c
- **Compatibility**: Output tÆ°Æ¡ng thÃ­ch vá»›i táº¥t cáº£ YOLO implementations

## ğŸ¤ Contributing

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request


## ğŸ‘¤ Author

**QuyDatSadBoy**
- GitHub: [@QuyDatSadBoy](https://github.com/QuyDatSadBoy)

---

*Project nÃ y lÃ  má»™t pháº§n cá»§a pipeline xá»­ lÃ½ dá»¯ liá»‡u cho training object detection models trÃªn video bÃ³ng Ä‘Ã¡.*
